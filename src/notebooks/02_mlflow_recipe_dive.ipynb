{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "566084ee-e3c6-49c3-9a21-c3edb84906b7",
   "metadata": {},
   "source": [
    "# MLflow with recipe\n",
    "\n",
    "In this second notebook we will take the same example than the first example but we will use MLflow recipe to accomplish the same result. \n",
    "We will go throught the same steps than on the first notebook but this time we will use the MLflow recipe module. \n",
    "\n",
    "Like on the previous notebook, you will have some tasks that need to be completed. You will be able to find where they are in the code by searching for `# ToDo#: ...`\n",
    "\n",
    "In this notebook, you will be asked to:\n",
    "* ToDo1: Add a column to indicate if the wine is red or white\n",
    "* ToDo2: specify split ratios for train, validation, and test sets\n",
    "* ToDo3: Create a Pipeline object that transforms the features\n",
    "* ToDo4: Create a LinearRegression estimator with the estimator_params\n",
    "* ToDo5: add custom metrics to our recipe\n",
    "* ToDo6: look in the UI what did the recipe logged by default. What was added compared with last notebook?\n",
    "* ToDo7: change the model uri to the one from current run\n",
    "* ToDo8: query the model with some test data\n",
    "* ToDo9: [To Go Further] use the AutoML estimator instead and use the UI to compare the results\n",
    "* ToDo10: [To Go Further] use databricks mlflow instead of local mlflow server\n",
    "\n",
    "If you need help you can browse through the following documentation:\n",
    "* [MLflow](https://mlflow.org/docs/latest/index.html), in particular the [recipe module](https://mlflow.org/docs/latest/recipes.html)\n",
    "* [MLflow recipe template](https://github.com/mlflow/recipes-regression-template)\n",
    "* [MLflow recipe example](https://github.com/mlflow/recipes-examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e252acf-a539-424c-8ccd-bc3ee7e50e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.recipes import Recipe\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc329e-ff52-46d3-bdc1-0a4b872343ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: please change the directory if you are not using a dev container.\n",
    "# We want to have the working directory to be the src folder in the mlflow-trainng repo\n",
    "os.chdir(\"/workspaces/mlflow-training/src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50b250-1f82-4f0a-ae7d-b636bc70a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Recipe(profile=\"local\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221a31d-847f-4b69-860d-387941ba2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.clean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8284f-05a1-48be-ad00-12f7d32c9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason you might have to run the cell twice before working\n",
    "r.inspect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57019d37-29da-4880-a773-9217d4ef3e3d",
   "metadata": {},
   "source": [
    "## Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913cc38e-9d06-430a-96b9-6fc60d4ad6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat steps/ingest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f26c97-9643-42ad-ad8a-3517790438e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"ingest\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a0b9316-6f32-4d3e-baf2-c22ffd9ebe40",
   "metadata": {},
   "source": [
    "## Split data\n",
    "\n",
    "We want to split the data to have the following proportion:\n",
    "- 80% training\n",
    "- 10% evaluation\n",
    "- 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790783c-f756-415d-a2ea-6188575cfe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat recipe.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5f970-b29d-4d6e-b7f8-5482d2fc4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"split\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57245f6-cefc-4e65-9a91-d27905f2bddc",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3e2dc-85cc-4f2e-9380-3a78757b4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat steps/transform.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6eda2-6f1e-4a35-99e4-ef33dd95d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"transform\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d660f0d-6bbd-489d-a784-c6e8effa85da",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f196ea-b320-43ec-872f-09b51a5c02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat steps/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat recipe.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e056628-cf59-4185-9416-92e1a97e620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e227e-8dbd-44fb-91e1-1778ef39e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9333b0f2-1bf9-49d3-8f4b-ec8899114bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"register\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"If you shut down mlflow server from notebook 01\")\n",
    "print(\n",
    "    \"Please copy the command below in a new terminal on your IDE and let it run until the end of the notebook \\n\"\n",
    ")\n",
    "\n",
    "print(\"mlflow server \\\\\")\n",
    "print(\"    --backend-store-uri sqlite:///src/metadata/mlflow/mlruns.db \\\\\")\n",
    "print(\"    --default-artifact-root ./src/metadata/mlflow/mlartifacts \\\\\")\n",
    "print(\"    --host 0.0.0.0 \\\\\")\n",
    "print(\"    --port 5000\")\n",
    "\n",
    "# ToDo6: look in the UI what did the recipe logged by default. What was added compared with last notebook?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7efa7a-8136-450f-891d-4561f7f43e30",
   "metadata": {},
   "source": [
    "## Predict with trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb8787-12e1-4675-89dd-362b8c043ce2",
   "metadata": {},
   "source": [
    "### Predict on batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4eab1-877d-46c2-8059-66dcf9a242fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: it takes around 5 minutes to run...\n",
    "# we can only run it locally, if you are using codespace it will break your environemt\n",
    "if \"GITHUB_CODESPACE_TOKEN\" not in os.environ:\n",
    "    r.run(\"predict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885e6f1-c6cc-42fc-8450-c5a0fc4eb1a6",
   "metadata": {},
   "source": [
    "### Predict in real time\n",
    "\n",
    "We can also use the mlflow model to do rediction in real-time. To do so we will need to:\n",
    "1. run an mlflow server to be able to distribute the model (like in notebook 01)\n",
    "2. create a serving enpoint which will pull the model from mlflow server\n",
    "3. finally we can query our model in real time using `curl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8b754-b5e0-4224-af3d-deb145e33ffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Please copy the command below in a new terminal on your IDE \\n\")\n",
    "\n",
    "print(\"MLFLOW_TRACKING_URI=http://0.0.0.0:5000 mlflow models serve \\\\\")\n",
    "print(\"      --host=0.0.0.0 \\\\\")\n",
    "print(\"      --port=5011 \\\\\")\n",
    "print(\"      --env-manager=local \\\\\")\n",
    "# ToDo7: change the model uri to the one from current run\n",
    "print(f\"      --model-uri ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a11070-4ca6-43af-979d-87dbafd1f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo8: query the model with some test data\n",
    "test_data = r.get_artifact(\"test_data\")\n",
    "request_data = test_data.iloc[0:4].to_json(orient=\"records\")\n",
    "print(\"You can copy the command below on one of your terminal \\n\")\n",
    "print(\n",
    "    \"\"\"curl http://0.0.0.0:5011/invocations -H 'Content-Type: application/json' -d '{\"dataframe_records\": \"\"\"\n",
    "    + request_data\n",
    "    + \"\"\"}'\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a55e6-4276-4ffe-a9e2-1cd8fe6f9deb",
   "metadata": {},
   "source": [
    "## To Go Further\n",
    "\n",
    "You can try to use `flaml` to get one of the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68086a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo9: [To Go Further] use the AutoML estimator instead and use the UI to compare the results\n",
    "!cat recipe.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d152443",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo10: [To Go Further] use databricks mlflow instead of local mlflow server\n",
    "# Note: you will need to have a databricks community account (free)\n",
    "# See ANNEXE.md for more details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d09ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
