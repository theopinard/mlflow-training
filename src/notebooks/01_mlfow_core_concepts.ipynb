{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de17c4d2-d2f5-4827-81da-c4c96655eb7e",
   "metadata": {},
   "source": [
    "# MLflow Core Concepts\n",
    "\n",
    "In this notebook you will build a model to predict the score quality of a wine given some physicochemical measurements. See [Cortez et al., 2009](http://www3.dsi.uminho.pt/pcortez/wine/) for more detail about the dataset. \n",
    "\n",
    "The goal of the notebook is to go through all the different stpes of putting a ML model to productions:\n",
    "* ingest the data\n",
    "* split the data for training and evaluation and test\n",
    "* transform the data for the model\n",
    "* train and evaluate the model\n",
    "* store the model\n",
    "* use the model above to predict on some new data (in batch or real-time)\n",
    "\n",
    "The goal of this notebook is to give some end-to-end flow. We are not trying to go very deep in any steps but show the overall flow. \n",
    "\n",
    "Along this notebook you will have some tasks that need to be completed. You will be able to find where they are in the code by searching for `# ToDo#: ...`\n",
    "\n",
    "In this notebooks you will be asked to:\n",
    "* ToDo1: add a column to the data frame that indicates if the wine is red or white\n",
    "* ToDo2: separate the target variable from the features\n",
    "* ToDo3: fit the preprocessing pipeline on the training data and transform the validation and test data\n",
    "* ToDo4: log the model and the preprocessing pipeline\n",
    "* ToDo5: log metrics to mlflow\n",
    "* ToDo6: log parameters to mlflow\n",
    "* ToDo7: go to see your model logged on mlflow and register the model in the UI and set the model stage to production\n",
    "* ToDo8: load the model from mlflow and make a prediction on the test data\n",
    "* ToDo9: set the model uri to the model you just registered\n",
    "* ToDo10: [To Go Further] rebuild a model using sklearn pipeline, log it to mlflow and deploy a serving endpoint\n",
    "\n",
    "If you need help you can browse through the following documentation:\n",
    "* [MLflow](https://mlflow.org/docs/latest/index.html)\n",
    "* [scikit-learn](https://scikit-learn.org/stable/)\n",
    "* [pandas](https://pandas.pydata.org/docs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a59df6-2a5a-40f4-b048-3d22d970a736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.base import BaseEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe7249-048e-48d7-aa47-31ba4c2ff139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: please change the directory if you are not using a dev container.\n",
    "# We want to have the working directory to be the src folder in the mlflow-trainng repo\n",
    "os.chdir(\"/workspaces/mlflow-training/src\")\n",
    "\n",
    "\n",
    "# setup mlflow to use the same setting than in the recipe in notebook 02\n",
    "from steps.utils import setup_mlflow\n",
    "\n",
    "setup_mlflow(\n",
    "    experiment_name=\"wine_score_notebook\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0331f-d035-434c-887e-c6a75aab8d8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ea347-a483-447e-ae92-2fb25374b2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "red_df = pd.read_csv(\n",
    "    \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "white_df = pd.read_csv(\n",
    "    \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "# ToDo1: add a column to the data frame that indicates if the wine is red or white\n",
    "...\n",
    "\n",
    "df = pd.concat([red_df, white_df])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07734044-b50c-4269-9050-69014e7735ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split data\n",
    "\n",
    "We want to split the data to have the following proportion:\n",
    "- 80% training\n",
    "- 10% evaluation\n",
    "- 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6752cce-edc0-448e-b08a-d23cd240214f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ToDo2: separate the target variable from the features\n",
    "y = ...\n",
    "X = ...\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test_val, y_test_val, test_size=0.5, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8d073-e665-45d8-a3d1-3923705623e6",
   "metadata": {},
   "source": [
    "## Transform data\n",
    "\n",
    "Apply a preprocessing step to by removing the mean and scaling to unit variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0903478-25e9-4c83-97ce-13c67cb6fd52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"ct\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"minmax\",\n",
    "                        StandardScaler(),\n",
    "                        X_train.columns,\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ToDo3: fit the preprocessing pipeline on the training data and transform the validation and test data\n",
    "X_train_processed = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_val_processed = preprocessing_pipeline.transform(X_val)\n",
    "X_test_processed = preprocessing_pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95b27b-5654-4281-8413-e1dc07410cb0",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b097a-579a-484b-8b36-972610a5f4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(\n",
    "    model: RegressorMixin, X: pd.DataFrame, y: pd.Series, suffix: str = \"test\"\n",
    ") -> dict:\n",
    "    \"\"\"Log model perfomance on dataset\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    metrics = {\n",
    "        f\"{suffix}.mean_absolute_error\": mae,\n",
    "        f\"{suffix}.mean_squared_error\": mse,\n",
    "        f\"{suffix}.r2_score\": r2,\n",
    "    }\n",
    "    # ToDo5: log metrics to mlflow\n",
    "    ...\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dfb29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_parameters(\n",
    "    model: BaseEstimator,\n",
    ") -> dict:\n",
    "    \"\"\"Log parameters of interest of the model\"\"\"\n",
    "    model_params = model.get_params()\n",
    "\n",
    "    # ToDo6: log parameters to mlflow\n",
    "    ...\n",
    "    return model_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b882852-131c-427a-9b34-67b95923bde4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    # ToDo4: log the model and the preprocessing pipeline\n",
    "    ...\n",
    "\n",
    "    # ToDo5: log metrics to mlflow (see above)\n",
    "    ...\n",
    "    # ToDo6: log parameters to mlflow (see above)\n",
    "    ...\n",
    "\n",
    "    # Note: we store the run id to be able to retrieve the run later\n",
    "    mlflow_run_id = run.info.run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cec48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Please copy the command below in a new terminal on your IDE and let it run until the end of the notebook \\n\"\n",
    ")\n",
    "\n",
    "print(\"mlflow server \\\\\")\n",
    "print(\"    --backend-store-uri sqlite:///src/metadata/mlflow/mlruns.db \\\\\")\n",
    "print(\"    --default-artifact-root ./src/metadata/mlflow/mlartifacts \\\\\")\n",
    "print(\"    --host 0.0.0.0 \\\\\")\n",
    "print(\"    --port 5000\")\n",
    "\n",
    "# ToDo7: go to see your model logged on mlflow and register the model in the UI and set the model stage to production\n",
    "# Note: mlflow ui by going to http://localhost:5000/ or http://0.0.0.0:5000/ in your browser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b150c-4d7c-4ee8-9bec-6c04070c8b4b",
   "metadata": {},
   "source": [
    "## Predict with trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1868c59b-3ad1-4464-9991-bda9193f47c6",
   "metadata": {},
   "source": [
    "### Predict on batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11fe35-e3fb-4626-99ff-7bfdc0cd45e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ToDo8: load the model from mlflow and make a prediction on the test data\n",
    "loaded_model = ...\n",
    "predictions = ...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa407eec-4161-4474-ad54-51cc5b4add9a",
   "metadata": {},
   "source": [
    "### Predict in real time\n",
    "\n",
    "We can also use the mlflow model to do rediction in real-time. To do so we will need to:\n",
    "1. run an mlflow server to be able to distribute the model (already done above)\n",
    "2. create a serving enpoint which will pull the model from mlflow server\n",
    "3. finally we can query our model in real time using `curl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5cc1f-b3f0-4fc0-92a3-b983ecefc063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Please copy the command below in a new terminal on your IDE \\n\")\n",
    "\n",
    "print(\"MLFLOW_TRACKING_URI=http://0.0.0.0:5000 mlflow models serve \\\\\")\n",
    "print(\"      --host=0.0.0.0 \\\\\")\n",
    "print(\"      --port=5001 \\\\\")\n",
    "print(\"      --env-manager=local \\\\\")\n",
    "# ToDo9: set the model uri to the model you just registered\n",
    "print(\"      --model-uri=...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a2491-2e31-4416-a690-304c8d7f204b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"You can copy the command below on one of your terminal \\n\")\n",
    "\n",
    "request_data = pd.DataFrame(X_test_processed).iloc[0:4].to_json(orient=\"records\")\n",
    "print(\n",
    "    \"\"\"curl http://0.0.0.0:5001/invocations -H 'Content-Type: application/json' -d '{\"dataframe_records\": \"\"\"\n",
    "    + request_data\n",
    "    + \"\"\"}'\"\"\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00ad5a65",
   "metadata": {},
   "source": [
    "Congratulation! You made it! \n",
    "\n",
    "If you still have some time you can take a big breach and try to help the people around you. \n",
    "\n",
    "Or if you like you can try to improve on what you already did and see what could be added "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55bb47-0a1e-410b-92ff-81de708ee77c",
   "metadata": {},
   "source": [
    "## To Go Further\n",
    "\n",
    "You can try to combine the transformer and the predictor together in the same sklearn pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a05828-ddea-4353-a33a-6698ef7b3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo10: [To Go Further] rebuild a model using sklearn pipeline, log it to mlflow and deploy a serving endpoint\n",
    "setup_mlflow(\n",
    "    experiment_name=\"wine_score_pipeline_notebook\",\n",
    ")\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a70b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
